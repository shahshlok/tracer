{
  "run_id": "run_2025-12-07_seed1765128549",
  "created_at": "2025-12-07T11:40:31.571159+00:00",
  "dataset": {
    "assignment": "A1",
    "seed": 1765128549,
    "generation_model": "gpt-5.1-2025-11-13",
    "generated_at": "2025-12-07T10:28:30.566632",
    "students": 100,
    "questions": 4,
    "total_files": 400,
    "seeded_files": 100,
    "seeded_pct": 25.0
  },
  "pipeline": {
    "detection_models": [
      "anthropic/claude-haiku-4.5",
      "anthropic/claude-haiku-4.5:reasoning",
      "google/gemini-2.5-flash-preview-09-2025",
      "google/gemini-2.5-flash-preview-09-2025:reasoning",
      "openai/gpt-5.1",
      "openai/gpt-5.1:reasoning"
    ],
    "strategies": [
      "baseline",
      "cot",
      "socratic",
      "taxonomy"
    ],
    "matchers": [
      "fuzzy_only",
      "semantic_only",
      "hybrid"
    ],
    "embedding_model": "text-embedding-3-large"
  },
  "results": {
    "by_matcher": {
      "fuzzy_only": {
        "avg_f1": 0.07538770441255059,
        "avg_precision": 0.05612503134154486,
        "avg_recall": 0.1260973597359736
      },
      "hybrid": {
        "avg_f1": 0.8867210339923958,
        "avg_precision": 0.8474972575310057,
        "avg_recall": 0.9317532408425935
      },
      "semantic_only": {
        "avg_f1": 0.8390958529355103,
        "avg_precision": 0.7668805923481035,
        "avg_recall": 0.9327131495903488
      }
    },
    "best_overall": {
      "matcher": "hybrid",
      "strategy": "cot",
      "model": "openai/gpt-5.1:reasoning",
      "f1": 0.9425287356321839
    }
  },
  "notes": ""
}
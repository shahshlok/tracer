{
  "run_id": "run_2025-12-06_seed1765036611",
  "created_at": "2025-12-06T08:47:42.228079+00:00",
  "dataset": {
    "assignment": "A2",
    "seed": 1765036611,
    "generation_model": "gpt-5.1-2025-11-13",
    "generated_at": "2025-12-06T07:56:51.470952",
    "students": 10,
    "questions": 4,
    "total_files": 40,
    "seeded_files": 10,
    "seeded_pct": 25.0
  },
  "pipeline": {
    "detection_models": [
      "anthropic/claude-haiku-4.5",
      "anthropic/claude-haiku-4.5:reasoning",
      "google/gemini-2.5-flash-preview-09-2025",
      "google/gemini-2.5-flash-preview-09-2025:reasoning",
      "openai/gpt-5.1",
      "openai/gpt-5.1:reasoning"
    ],
    "strategies": [
      "baseline",
      "cot",
      "socratic",
      "taxonomy"
    ],
    "matchers": [
      "fuzzy_only",
      "semantic_only",
      "hybrid"
    ],
    "embedding_model": "text-embedding-3-large"
  },
  "results": {
    "by_matcher": {
      "fuzzy_only": {
        "avg_f1": 0.0,
        "avg_precision": 0.0,
        "avg_recall": 0.0
      },
      "hybrid": {
        "avg_f1": 0.5896085154525342,
        "avg_precision": 0.5650810416435416,
        "avg_recall": 0.6266511266511267
      },
      "semantic_only": {
        "avg_f1": 0.5733162935980936,
        "avg_precision": 0.5489877599252599,
        "avg_recall": 0.6105040792540792
      }
    },
    "best_overall": {
      "matcher": "hybrid",
      "strategy": "taxonomy",
      "model": "openai/gpt-5.1",
      "f1": 0.9473684210526316
    }
  },
  "notes": ""
}
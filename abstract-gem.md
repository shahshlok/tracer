The Sycophantic Tutor: Benchmarking the Pedagogical Risks of Over-Diagnosis in LLM-Based CS1 Feedback

As LLM-based tutors are rapidly deployed in introductory computer science (CS1) classrooms, they are primarily evaluated on their ability to fix bugs or generate code. We argue that this "fix-focused" evaluation paradigm obscures a critical, high-stakes failure mode: **hallucinated pedagogical diagnosis**. Effective tutoring requires accurately inferring a student's *notional machine*—their mental model of computation—but we demonstrate that current LLMs exhibit a dangerous bias toward inventing misconceptions where none exist.

To quantify this risk, we introduce TRACER, a label-blind evaluation framework that treats diagnosis as a narrative justification task. We benchmark leading LLMs against a controlled dataset of 1,200 CS1 Java submissions, comprising both correct code and code seeded with 18 distinct notional machine misconceptions.

Our findings reveal a disturbing "sycophancy" in diagnostic behavior. While LLMs achieve high recall (0.87) in identifying genuine misconceptions, they fail significantly on precision (0.58). Crucially, **86.6% of false positives occur on effectively correct code**, meaning the tutor effectively "gaslights" students by inventing deep conceptual flaws to explain non-existent errors. Furthermore, when ablated with label-aware prompts—mimicking common "describe the error" workflows—specificity collapses further (from 0.85 to 0.77) while recall saturates (0.98), confirming that LLMs prioritize plausibility over truth when primed.

We posit that the prevailing metric for AI tutors—diagnostic recall—is actively harmful. In educational contexts, a missed diagnosis is merely a missed learning opportunity, but a false diagnosis is an active impediment to learning that erodes student confidence. We propose a paradigm shift in evaluation: from **bug detection** to **diagnostic safety**, prioritizing metrics that penalize over-diagnosis and reward systems that know when to remain silent.

# Future Improvements for Misconception Analysis

Progression Analysis is hardcoded to Q3 and Q4. Future improvements:

- Allow user to specify which assignments to compare
- Allow user to specify which misconceptions to compare
- Allow user to specify which students to compare

## 1. Ensemble Model Approach for Misconception Detection

Currently using individual LLM outputs. Future improvements:

### Weighted Ensemble Voting
- Multiple models vote on misconceptions
- Weight votes by model confidence and historical accuracy
- Only report misconceptions above a threshold (e.g., 2/3 models agree)

### Agreement-Based Confidence
- Single model detection: low confidence
- 2 models agree: medium confidence  
- All models agree: high confidence
- Use this as a filter or weighting factor in aggregation

### Model Calibration
- Track which models over-detect vs under-detect misconceptions
- Calibrate confidence scores based on validation data

## 2. "Most Common" Metric Improvements

Current: Raw occurrence count

Future options to explore:
- **Weighted by model agreement**: misconceptions detected by multiple models count more
- **Normalized by submissions**: account for varying submission counts per question
- **Severity weighting**: misconceptions causing more point loss weighted higher
- **Persistence bonus**: misconceptions appearing across multiple questions for same student

## 3. Question Redesign Identification

Add automated flagging for questions that need attention:
- High misconception rate (>X% of students)
- Specific misconceptions dominating (single issue >50% of all misconceptions)
- Low score variance (everyone struggles equally = bad question design?)
- Mismatch between intended topic and detected misconceptions

## 4. Model Agreement as Validity Signal

Options to implement:
- (A) Only report misconceptions where models agree (higher precision, fewer false positives)
- (B) Report all but flag agreement level (higher recall, shows full picture)
- (C) Use agreement as weighting factor in all aggregations

Decision pending based on validation with ground truth data.

## 5. Advanced Analytics

### Misconception Clustering
- Use embeddings to cluster similar misconception descriptions
- Reduce fragmentation in LLM-generated labels
- Auto-generate canonical misconception names

### Temporal Analysis
- Track misconceptions across multiple assignments
- Identify persistent vs one-time issues
- Measure learning progression

### Student Risk Scoring
- Aggregate misconception patterns into risk score
- Flag students for early intervention
- Predict likelihood of course failure

## 6. Topic Mapping Improvements

Current: Manual mapping of LLM topics to 4 canonical topics

Future:
- Use LLM to auto-classify topics into canonical categories
- Build a mapping table from historical data
- Handle edge cases and ambiguous topics programmatically

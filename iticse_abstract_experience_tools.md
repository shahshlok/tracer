# ITiCSE Experience Reports and Tools (ERT) Track Abstract

LLMs are increasingly used for CS1 tutoring, but evaluating whether they diagnose students’ underlying notional machines (not just surface bugs) is difficult. We present TRACER, a tool-supported evaluation framework for narrative fidelity: given a student program, an LLM must articulate the student’s belief as a short narrative, and TRACER scores alignment to reference misconception narratives via semantic similarity with cross-validated decision thresholds. TRACER includes a controlled synthetic benchmark of 1,200 Java CS1 programs with 18 seeded misconceptions (275 seeded; 925 clean controls) validated by compilation and hidden tests, enabling measurement of both detection and false-alarm rates. We demonstrate TRACER by benchmarking three LLM families across four prompting strategies. In the label-blind setting, performance is high-recall but over-diagnoses misconceptions (precision 0.577, recall 0.872, specificity 0.848). Exposing misconception identities increases recall (0.982) but reduces specificity (0.774), indicating label leakage can worsen over-diagnosis. We provide artifacts and reporting to help researchers and instructors compare tutoring prompts/models and to encourage safer deployments where diagnoses are treated as hypotheses.


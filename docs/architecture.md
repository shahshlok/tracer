# Architecture: The Complete Research Pipeline

This document explains the entire TRACER system from start to finish. It assumes no prior knowledge and includes detailed diagrams and exhaustive explanations for beginners.

---

## What is TRACER?

TRACER is a **research pipeline** that automatically diagnoses student **mental models** (misconceptions about how programming concepts work) by:

1. **Creating synthetic student code** with known bugs
2. **Running 6 different LLMs** with 4 different prompting strategies  
3. **Comparing LLM outputs** to ground truth misconceptions using semantic embeddings
4. **Measuring accuracy** through rigorous 5-fold cross-validation

The goal: Understand the **limits** of what LLMs can diagnose about **how students think**, not just **what bugs exist**.

---

## Quick Overview: The Four-Stage Pipeline

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           WHAT WE MEASURE                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Traditional Code Analysis        vs        Mental Model Diagnosis          │
│   ─────────────────────────────              ──────────────────────────      │
│                                                                             │
│   "Line 5 has an array index       vs   "Student believes arrays start      │
│    out of bounds error"                  at index 1, like in mathematics"   │
│                                                                             │
│   ↓ Identifies symptom                   ↓ Identifies cognitive cause       │
│   ↓ Any static analyzer can do this     ↓ Requires understanding intent    │
│                                                                             │
│   This framework measures whether LLMs can do the SECOND type.              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## The 4-Stage Pipeline

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                          COMPLETE RESEARCH PIPELINE                           │
└──────────────────────────────────────────────────────────────────────────────┘

  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
  │    STAGE 1      │    │    STAGE 2      │    │    STAGE 3      │    │    STAGE 4      │
  │   SYNTHETIC     │───▶│     BLIND       │───▶│    SEMANTIC     │───▶│    ENSEMBLE     │
  │   INJECTION     │    │   DETECTION     │    │   ALIGNMENT     │    │     VOTING      │
  └─────────────────┘    └─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                      │                      │
         │                       │                      │                      │
         ▼                       ▼                      ▼                      ▼

   ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
   │ • 18 misconcp-  │    │ • 6 LLM models  │    │ • OpenAI embed- │    │ • Require ≥2    │
   │   tions defined │    │ • 4 prompts     │    │   dings (3072D) │    │   strategies    │
   │ • 300 students  │    │ • 900 files     │    │ • Cosine sim-   │    │   to agree      │
   │ • 1 bug/file    │    │ • 21,600 outputs│    │   ilarity ≥0.55 │    │ • Filters 92%   │
   │                 │    │                 │    │                 │    │   of false pos  │
   └─────────────────┘    └─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                      │                      │
         ▼                       ▼                      ▼                      ▼

   authentic_seeded/      detections/              TP/FP/FN            Final metrics:
   ├── a1/                ├── a1_multi/            classification      Strategy: P=0.640, F1=0.737
   ├── a2/                ├── a2_multi/                                Model: P=0.684, F1=0.763
   └── a3/                └── a3_multi/
```

---

## Stage 1: Synthetic Injection

### Purpose
Create a dataset of student code with **known, labeled misconceptions** that can serve as ground truth for evaluation.

> **Important:** The data is 100% synthetically generated by `gpt-5.1-2025-11-13`, not from real students. See **[Dataset Generation](dataset-generation.md)** for full details on the pipeline, persona matrix, and limitations.

### Process

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         SYNTHETIC INJECTION PROCESS                          │
│                                                                             │
│                      Generator Model: gpt-5.1-2025-11-13                    │
└─────────────────────────────────────────────────────────────────────────────┘

  INPUT: groundtruth.json                    OUTPUT: Student Java files
  ───────────────────────                    ────────────────────────────

  {                                          // Student: Allen_Andrew_600171
    "id": "NM_STATE_01",                     // Question: Q1 (Acceleration)
    "category": "Reactive State Machine",   
    "name": "Spreadsheet View",              double v0 = 0, v1 = 0, t = 0;
    "student_thinking": "Variables           double a = (v1 - v0) / t;  // Bug!
      update automatically when              v0 = scan.nextDouble();
      their sources change"                  v1 = scan.nextDouble();
  }                                          t = scan.nextDouble();
        │                                    System.out.println(a);
        │                                           │
        ▼                                           │
  GPT-5.1 generates code                            │
  that exhibits this                                ▼
  misconception                              authentic_seeded/a1/
                                             Allen_Andrew_600171/Q1.java
```

### Key Files

| File | Purpose |
|------|---------|
| `data/a1/groundtruth.json` | 8 misconception definitions for A1 |
| `data/a2/groundtruth.json` | 6 misconception definitions for A2 |
| `data/a3/groundtruth.json` | 4 misconception definitions for A3 |
| `utils/generators/dataset_generator.py` | 6-step generation pipeline |

### Important Constraints

- **One misconception per file.** Each file has exactly one ground truth ID (or none if "clean").
- **3 clean + 1 seeded per student.** Enables false positive measurement.
- **Validated by compilation and tests.** Seeded code must compile AND fail at least one test.

---

## Stage 2: Blind Detection

### Purpose
Have LLMs analyze student code **without knowing the ground truth**, to measure their natural diagnostic ability.

### Detection Grid

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              DETECTION MATRIX                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                              PROMPTING STRATEGIES                            │
│               ┌──────────┬──────────┬──────────┬──────────┐                 │
│               │ baseline │ taxonomy │   cot    │ socratic │                 │
│ ┌─────────────┼──────────┼──────────┼──────────┼──────────┤                 │
│ │ GPT-5.2     │    ●     │    ●     │    ●     │    ●     │                 │
│ │ GPT-5.2:r   │    ●     │    ●     │    ●     │    ●     │                 │
│ │ Claude      │    ●     │    ●     │    ●     │    ●     │                 │
│ │ Claude:r    │    ●     │    ●     │    ●     │    ●     │                 │
│ │ Gemini      │    ●     │    ●     │    ●     │    ●     │                 │
│ │ Gemini:r    │    ●     │    ●     │    ●     │    ●     │                 │
│ └─────────────┴──────────┴──────────┴──────────┴──────────┘                 │
│                                                                             │
│  6 models × 4 strategies = 24 detection configurations                      │
│  24 configs × 360 files = 8,640 total detections                            │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Prompting Strategies

| Strategy | Description | Example Prompt Excerpt |
|----------|-------------|----------------------|
| **baseline** | Simple bug-finding | "Identify any misconceptions in this code" |
| **taxonomy** | Provides category list | "Given these categories: [list], which applies?" |
| **cot** | Chain-of-thought tracing | "Trace line-by-line, then identify misconceptions" |
| **socratic** | Mental model probing | "What does the student believe about how Java works?" |

### LLM Output Schema

Every detection produces structured JSON:

```json
{
  "misconceptions": [
    {
      "inferred_category_name": "Early Calculation Error",
      "student_thought_process": "Student believes variables update automatically...",
      "conceptual_gap": "Variables are assigned once, not reactive",
      "evidence": [
        {"line_number": 3, "code_snippet": "double a = (v1 - v0) / t;"}
      ],
      "confidence": 0.85
    }
  ]
}
```

### Key Files

| File | Purpose |
|------|---------|
| `prompts/strategies.py` | 4 prompt builders |
| `miscons.py` | Detection orchestrator |
| `utils/llm/*.py` | API clients (OpenAI, Anthropic, Google) |
| `detections/{a}_multi/{strategy}/` | Output directory |

---

## Stage 3: Semantic Alignment

### Purpose
Match LLM outputs to ground truth despite **terminology differences**. An LLM might call it "Auto-Update Error" while we call it "Reactive State Machine"—same concept, different words.

### The Matching Problem

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                            THE TERMINOLOGY GAP                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  LLM Output:              "Student thinks variables auto-update"            │
│  Ground Truth:            "NM_STATE_01: Reactive State Machine"             │
│                                                                             │
│  String matching:         0% overlap                                         │
│  Semantic similarity:     87% match ✓                                        │
│                                                                             │
│  We use SEMANTIC EMBEDDINGS to bridge this gap.                             │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Embedding Pipeline

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          SEMANTIC MATCHING PROCESS                           │
└─────────────────────────────────────────────────────────────────────────────┘

  LLM Detection Text                          Ground Truth Definitions
  ──────────────────                          ────────────────────────

  "Student computed formula         ←─────→   NM_STATE_01: "Variables are
   before reading inputs,                     treated like spreadsheet cells
   expecting auto-update"                     that update automatically"

         │                                            │
         ▼                                            ▼

  OpenAI text-embedding-3-large             OpenAI text-embedding-3-large
  [0.12, -0.45, 0.78, ...]                  [0.15, -0.42, 0.81, ...]
  (3072 dimensions)                         (3072 dimensions)

                         │
                         ▼

               Cosine Similarity = 0.87

                         │
                         ▼

               0.87 ≥ 0.55 threshold?
                      YES ✓
                         │
                         ▼

               MATCH: NM_STATE_01
               Classification: TRUE POSITIVE
```

### Thresholds

These thresholds were **calibrated on the dev set** (80% of data, seed=42) using grid search over 6×5 configurations. They generalize perfectly to the test set (mean dev-test gap = 0.000).

| Threshold | Value | Purpose |
|-----------|-------|---------|
| **Noise Floor** | 0.55 | Cosine similarity below this = pedantic observations (resource management, naming), filtered without counting |
| **Semantic Threshold** | 0.60 | Score in 0.55-0.60 range = uncertain match (counted as FP), ≥0.60 = confident match (checked against ground truth) |

### Classification Rules

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          CLASSIFICATION LOGIC                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Score < 0.55:     NOISE (discarded, not counted)                           │
│                    "Didn't close Scanner" - pedantic, not misconception     │
│                                                                             │
│  Score 0.55-0.60:  FALSE POSITIVE (uncertain detection)                     │
│                    LLM claimed something with low confidence                │
│                                                                             │
│  Score ≥ 0.55:     Check if best_match_id == expected_id                    │
│                    ├── YES: TRUE POSITIVE (correct detection)               │
│                    └── NO:  FALSE POSITIVE (wrong misconception)            │
│                                                                             │
│  No detection:     FALSE NEGATIVE (missed the bug)                          │
│                                                                             │
│  Note: Noise floor (0.60) filters out spurious matches. Real TP scores     │
│  typically cluster around 0.70, FP scores around 0.65.                      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Key Files

| File | Purpose |
|------|---------|
| `utils/matching/semantic.py` | OpenAI embedding + cosine similarity |
| `analyze.py` | Main analysis with matching logic |

---

## Stage 4: Ensemble Voting

### Purpose
Reduce hallucinations by requiring **consensus** across strategies. If only 1 of 4 strategies detects something, it's likely a false positive.

### The Voting Algorithm

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          ENSEMBLE VOTING LOGIC                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  For each (student, question, misconception_id) tuple:                      │
│                                                                             │
│      Count how many strategies detected it:                                  │
│      ┌─────────────┬──────────────────────────────────────┐                 │
│      │ baseline    │ Detected NM_STATE_01? YES            │                 │
│      │ taxonomy    │ Detected NM_STATE_01? YES            │                 │
│      │ cot         │ Detected NM_STATE_01? NO             │                 │
│      │ socratic    │ Detected NM_STATE_01? YES            │                 │
│      └─────────────┴──────────────────────────────────────┘                 │
│                                                                             │
│      Agreement count: 3/4                                                    │
│      Threshold: ≥2                                                          │
│      Result: VALIDATED ✓                                                     │
│                                                                             │
│  ────────────────────────────────────────────────────────────────────────── │
│                                                                             │
│      Example of REJECTION:                                                  │
│      ┌─────────────┬──────────────────────────────────────┐                 │
│      │ baseline    │ Detected "Redundant Logic"? NO       │                 │
│      │ taxonomy    │ Detected "Redundant Logic"? NO       │                 │
│      │ cot         │ Detected "Redundant Logic"? NO       │                 │
│      │ socratic    │ Detected "Redundant Logic"? YES      │  ← hallucination│
│      └─────────────┴──────────────────────────────────────┘                 │
│                                                                             │
│      Agreement count: 1/4                                                    │
│      Threshold: ≥2                                                          │
│      Result: REJECTED (filtered out)                                         │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Impact of Ensemble Voting

| Metric | Raw | Strategy Ensemble (≥2/4) | Model Ensemble (≥2/6) |
|--------|-----|--------------------------|----------------------|
| Precision | 0.322 | 0.640 (+99%) | **0.684** (+112%) |
| Recall | 0.868 | 0.868 (stable) | 0.862 |
| F1 | 0.469 | 0.737 (+57%) | **0.763** (+63%) |

---

## Directory Structure

```
ensemble-eval-cli/
│
├── data/                               # GROUND TRUTH DEFINITIONS
│   ├── a1/
│   │   ├── groundtruth.json            # 8 misconceptions for Variables/Math
│   │   ├── a1.md                       # Assignment description
│   │   ├── q1.md, q2.md, q3.md         # Question prompts
│   │   └── tests/                      # Test cases
│   ├── a2/                             # 6 misconceptions for Loops/Control
│   └── a3/                             # 4 misconceptions for Arrays/Strings
│
├── authentic_seeded/                   # GENERATED STUDENT CODE
│   ├── a1/
│   │   ├── manifest.json               # Student → misconception mapping
│   │   └── {Student_Name}/
│   │       ├── a1q1.java               # Student submission Q1
│   │       ├── a1q2.java               # Student submission Q2
│   │       └── a1q3.java               # Student submission Q3
│   ├── a2/                             # 100 students × 3 questions
│   └── a3/                             # 100 students × 3 questions
│
├── detections/                         # LLM DETECTION OUTPUTS
│   ├── a1_multi/
│   │   ├── baseline/                   # Strategy: baseline
│   │   │   └── {model}/*.json          # Per-model outputs
│   │   ├── taxonomy/
│   │   ├── cot/
│   │   └── socratic/
│   ├── a2_multi/
│   └── a3_multi/
│
├── runs/                               # ANALYSIS RESULTS
│   └── multi/
│       └── run_final_analysis_100/     # FINAL RESULTS
│           ├── report.md               # Full markdown report
│           ├── metrics.json            # Numeric metrics
│           ├── results.csv             # Per-file breakdown
│           ├── compliance.csv          # TP/FP/FN per file
│           └── assets/                 # PNG visualizations
│               ├── assignment_comparison.png
│               ├── model_comparison.png
│               ├── strategy_f1.png
│               ├── category_recall.png
│               └── ...
│
├── prompts/
│   └── strategies.py                   # 4 prompt builders
│
├── pydantic_models/
│   ├── evaluation.py                   # DetectionResult schema
│   └── submission/models.py            # Student submission schema
│
├── utils/
│   ├── llm/
│   │   ├── openai.py                   # OpenAI client
│   │   ├── anthropic.py                # Anthropic client
│   │   └── gemini.py                   # Google client
│   ├── matching/
│   │   └── semantic.py                 # Embedding pipeline
│   ├── generators/
│   │   └── dataset_generator.py        # Synthetic data generation
│   └── statistics.py                   # Bootstrap CI, McNemar's test
│
├── docs/                               # DOCUMENTATION
├── analyze.py                          # Main analysis CLI
└── miscons.py                          # Detection orchestrator
```

---

## Data Models

### Ground Truth Schema (`groundtruth.json`)

```json
{
  "misconceptions": [
    {
      "id": "NM_STATE_01",
      "category": "The Reactive State Machine",
      "name": "Spreadsheet View (Early Calculation)",
      "explanation": "The student treats variables like spreadsheet cells...",
      "student_thinking": "I'll define the formula first, then read inputs...",
      "code_pattern": "Compute derived value BEFORE reading dependent inputs",
      "applicable_questions": ["Q1", "Q2", "Q3"]
    }
  ]
}
```

### Manifest Schema (`manifest.json`)

```json
{
  "students": [
    {
      "name": "Allen_Andrew_600171",
      "questions": {
        "Q1": {"is_clean": false, "misconception_id": "NM_STATE_01"},
        "Q2": {"is_clean": true, "misconception_id": null},
        "Q3": {"is_clean": false, "misconception_id": "NM_TYP_01"}
      }
    }
  ]
}
```

### Detection Output Schema

```json
{
  "student": "Allen_Andrew_600171",
  "question": "Q1",
  "strategy": "baseline",
  "model": "gpt-5.2",
  "misconceptions": [
    {
      "inferred_category_name": "string",
      "student_thought_process": "string",
      "conceptual_gap": "string",
      "evidence": [{"line_number": 3, "code_snippet": "..."}],
      "confidence": 0.85
    }
  ]
}
```

---

## Technology Stack

| Component | Technology | Version |
|-----------|------------|---------|
| Package Manager | uv | Latest |
| Python | Python | 3.12+ |
| LLM APIs | OpenRouter, OpenAI, Anthropic, Google | Latest |
| Embeddings | OpenAI text-embedding-3-large | 3072D |
| Data Processing | pandas, numpy | Latest |
| Statistics | scipy | Latest |
| Visualization | matplotlib, seaborn | Latest |
| CLI | typer | Latest |
| Validation | pydantic | v2 |

---

## Previous: [README](../README.md) | Next: [Dataset Generation](dataset-generation.md)

# Misconception Clustering with Fuzzy Matching

## Overview
This document explains the fuzzy clustering mechanism implemented in the `MisconceptionAnalyzer` to aggregate similar misconception names generated by LLMs.

## The Problem: Fragmentation
LLMs are creative and inconsistent. For the same underlying error, different models (or even the same model) might output:
- "Incorrect formula application"
- "Formula Misapplication"
- "Incorrect application of formula"

Without clustering, these appear as **3 separate misconceptions** with 1 occurrence each. This dilutes the data, making it hard to see that "Formula issues" are actually a major problem (3 occurrences).

## The Solution: Fuzzy Clustering
We use the `difflib.SequenceMatcher` from Python's standard library to identify and group similar strings based on their similarity ratio.

### Algorithm
1.  **Frequency Sorting**: We start by sorting all unique misconception names by their frequency (most common first). This establishes the most frequent names as the "canonical" centers for clusters.
2.  **Iterative Matching**: We iterate through the sorted list:
    - For each name, we compare it against existing canonical names.
    - We calculate a **similarity ratio** (0.0 to 1.0).
    - If the ratio exceeds the **threshold (0.8)**, the name is merged into the existing cluster.
    - If no match is found, it becomes a new canonical name.

### Why 0.8 Threshold?
The threshold of `0.8` was chosen empirically to balance precision and recall:
- **> 0.8**: Merges highly similar phrases (e.g., "Missing Semicolon" vs "Missing semicolon").
- **< 0.8**: Keeps distinct concepts separate (e.g., "Syntax Error" vs "Logic Error").

### Example Results
In our tests, this algorithm successfully merged:
- `Incorrect data type usage` absorbed `Incorrect Data Type Selection` (Ratio: ~0.82)
- `Misinterpreting Problem Requirements` absorbed `Misinterpretation of Problem Requirements` (Ratio: ~0.91)
- `Incorrect use of exponentiation operator` absorbed `Incorrect exponentiation operator` (Ratio: ~0.90)

## Implementation Details
The core logic resides in `utils/misconception_analyzer.py`:

```python
def cluster_misconceptions(self, threshold: float = 0.8) -> dict[str, str]:
    # ... (implementation using difflib)
    return clusters  # Maps original_name -> canonical_name
```

This mapping is applied during the `analyze_class` phase, ensuring that all subsequent reports (Markdown, CLI tables) reflect the aggregated counts.

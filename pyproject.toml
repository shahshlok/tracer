[project]
name = "ensemble-eval-cli"
version = "1.0.0"
description = "Modular Ensembling Method Evaluation harness for GPT-5 vs EduAI with SQLite 3.51.0+ JSONB database"
authors = [{ name = "Research Automation", email = "research@example.com" }]
requires-python = ">=3.10"
dependencies = [
  "openai>=1.50.0",
  "python-dotenv>=1.0.1",
  "rich>=13.7.0",
  "typer>=0.9.0",
  "jsonschema>=4.20.0",
  "pydantic>=2.0.0",
  "requests>=2.32.5",
  "python-dotenv>=1.0.0",
  "instructor>=1.13.0",
]

[project.optional-dependencies]
dev = [
  "pytest>=7.0.0",
  "ruff>=0.1.0",
]

[project.scripts]
bench = "cli:app"
experiment = "experiment.single_submission:main"
eme-validate = "validate_data:main"
eme-load = "run_loader:main"
eme-analyze = "run_analyzer:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["prompts", "utils", "db"]
include = ["main.py", "README.md", "data", "docs"]

[tool.uv]
# UV-specific configuration for November 2025
dev-dependencies = [
  "pytest>=7.0.0",
  "ruff>=0.1.0",
  "pytest-asyncio>=1.3.0",
]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = [
  "E",  # pycodestyle errors
  "W",  # pycodestyle warnings
  "F",  # pyflakes
  "I",  # isort
  "B",  # flake8-bugbear
  "C4", # flake8-comprehensions
  "UP", # pyupgrade
]
ignore = [
  "E501", # Line too long
]


[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
